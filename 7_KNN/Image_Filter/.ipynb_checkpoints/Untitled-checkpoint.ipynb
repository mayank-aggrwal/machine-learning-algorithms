{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noses: 1\n",
      "eyes: 1\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "def overlay_transparent(background_img, img_to_overlay_t, glass, x, y, z, v, overlay_size=None, os=None):\n",
    "#     \"\"\"\n",
    "# \t@brief      Overlays a transparant PNG onto another image using CV2\n",
    "\n",
    "# \t@param      background_img    The background image\n",
    "# \t@param      img_to_overlay_t  The transparent image to overlay (has alpha channel)\n",
    "# \t@param      x                 x location to place the top-left corner of our overlay\n",
    "# \t@param      y                 y location to place the top-left corner of our overlay\n",
    "# \t@param      overlay_size      The size to scale our overlay to (tuple), no scaling if None\n",
    "\t\n",
    "# \t@return     Background image with overlay on top\n",
    "# \t\"\"\"\n",
    "\n",
    "    bg_img = background_img.copy()\n",
    "\n",
    "    if overlay_size is not None:\n",
    "        img_to_overlay_t = cv2.resize(img_to_overlay_t.copy(), overlay_size)\n",
    "        glass = cv2.resize(glass.copy(), os)\n",
    "\n",
    "# \tExtract the alpha mask of the RGBA image, convert to RGB \n",
    "    b,g,r,a = cv2.split(img_to_overlay_t)\n",
    "    bg,gg,rg,ag = cv2.split(glass)\n",
    "    overlay_color = cv2.merge((b,g,r))\n",
    "    overlay_colorg = cv2.merge((bg,gg,rg))\n",
    "\n",
    "# \tApply some simple filtering to remove edge noise\n",
    "    mask = cv2.medianBlur(a,5)\n",
    "    maskg = cv2.medianBlur(ag,5)\n",
    "\n",
    "    h, w, _ = overlay_color.shape\n",
    "    hg, wg, _g = overlay_colorg.shape\n",
    "    roi = bg_img[y:y+h, x:x+w]\n",
    "    roig = bg_img[v:v+hg, z:z+wg]\n",
    "\n",
    "# \tBlack-out the area behind the logo in our original ROI\n",
    "    img1_bg = cv2.bitwise_and(roi.copy(),roi.copy(),mask = cv2.bitwise_not(mask))\n",
    "    img1_bgg = cv2.bitwise_and(roig.copy(),roig.copy(),mask = cv2.bitwise_not(maskg))\n",
    "\n",
    "# \tMask out the logo from the logo image.\n",
    "    img2_fg = cv2.bitwise_and(overlay_color,overlay_color,mask = mask)\n",
    "    img2_fgg = cv2.bitwise_and(overlay_colorg,overlay_colorg,mask = maskg)\n",
    "\n",
    "    # Update the original image with our new ROI\n",
    "    bg_img[y:y+h, x:x+w] = cv2.add(img1_bg, img2_fg)\n",
    "    bg_img[v:v+hg, z:z+wg] = cv2.add(img1_bgg, img2_fgg)\n",
    "\n",
    "    return bg_img\n",
    "\n",
    "\n",
    "nose_cascade = cv2.CascadeClassifier('Nose18x15.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('frontalEyes35x16.xml')\n",
    "m = cv2.imread('mustache.png', -1)\n",
    "g = cv2.imread('glasses.png', -1)\n",
    "i = cv2.imread('Jamie_Before.jpg')\n",
    "\n",
    "\n",
    "grayFrame = cv2.cvtColor(i, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "noses = nose_cascade.detectMultiScale(grayFrame, scaleFactor = 1.3, minNeighbors = 9, minSize = (30, 30), flags = cv2.CASCADE_SCALE_IMAGE)\n",
    "eyes = eye_cascade.detectMultiScale(grayFrame, scaleFactor = 1.3, minNeighbors = 3, minSize = (30, 30), flags = cv2.CASCADE_SCALE_IMAGE)\n",
    "print('noses:', len(noses))\n",
    "print('eyes:', len(eyes))\n",
    "\n",
    "\n",
    "# cv2.imshow('Pic',overlay_transparent(i, m, noses[0][0] - 4, noses[0][1] + noses[0][3] - 52, (140,80)))\n",
    "# cv2.imshow('Pic',overlay_transparent(i, g, eyes[0][0] - 17, eyes[0][1] - 15, (400,200)))\n",
    "img = overlay_transparent(i, g, m, eyes[0][0] - 13, eyes[0][1] - 20, noses[0][0] - 4, noses[0][1] + noses[0][3] - 52, (400,215), (140,80))\n",
    "cv2.imshow('Pic', img)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('Pic', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024, 733, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlay_transparent(background_img, img_to_overlay_t, glass, x, y, z, v, overlay_size=None, os=None):\n",
    "\n",
    "    bg_img = background_img.copy()\n",
    "\n",
    "    if overlay_size is not None:\n",
    "        img_to_overlay_t = cv2.resize(img_to_overlay_t.copy(), overlay_size)\n",
    "        glass = cv2.resize(glass.copy(), os)\n",
    "\n",
    "#  Extract the alpha mask of the RGBA image, convert to RGB \n",
    "    b,g,r,a = cv2.split(img_to_overlay_t)\n",
    "#     bg,gg,rg,ag = cv2.split(glass)\n",
    "    overlay_color = cv2.merge((b,g,r))\n",
    "#     overlay_colorg = cv2.merge((bg,gg,rg))\n",
    "\n",
    "#  Apply some simple filtering to remove edge noise\n",
    "    mask = cv2.medianBlur(a,5)\n",
    "#     maskg = cv2.medianBlur(ag,5)\n",
    "\n",
    "    h, w, _ = overlay_color.shape\n",
    "#     hg, wg, _g = overlay_colorg.shape\n",
    "    roi = bg_img[y:y+h, x:x+w]\n",
    "#     roig = bg_img[v:v+hg, z:z+wg]\n",
    "\n",
    "#  Black-out the area behind the logo in our original ROI\n",
    "    img1_bg = cv2.bitwise_and(roi.copy(),roi.copy(),mask = cv2.bitwise_not(mask))\n",
    "#     img1_bgg = cv2.bitwise_and(roig.copy(),roig.copy(),mask = cv2.bitwise_not(maskg))\n",
    "\n",
    "#  Mask out the logo from the logo image.\n",
    "    img2_fg = cv2.bitwise_and(overlay_color,overlay_color,mask = mask)\n",
    "#     img2_fgg = cv2.bitwise_and(overlay_colorg,overlay_colorg,mask = maskg)\n",
    "\n",
    "#  Update the original image with our new ROI\n",
    "    bg_img[y:y+h, x:x+w] = cv2.add(img1_bg, img2_fg)\n",
    "#     bg_img[v:v+hg, z:z+wg] = cv2.add(img1_bgg, img2_fgg)\n",
    "\n",
    "    return bg_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imread?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noses: 1\n",
      "eyes: 1\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.4.0) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-2y91i_7w\\opencv\\modules\\core\\src\\arithm.cpp:250: error: (-215:Assertion failed) (mtype == CV_8U || mtype == CV_8S) && _mask.sameSize(*psrc1) in function 'cv::binary_op'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-2af264923580>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;31m# cv2.imshow('Pic',overlay_transparent(i, m, noses[0][0] - 4, noses[0][1] + noses[0][3] - 52, (140,80)))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;31m# cv2.imshow('Pic',overlay_transparent(i, g, eyes[0][0] - 17, eyes[0][1] - 15, (400,200)))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moverlay_transparent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meyes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meyes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnoses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnoses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnoses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Pic'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-61ce49b6ac43>\u001b[0m in \u001b[0;36moverlay_transparent\u001b[1;34m(background_img, img_to_overlay_t, glass, x, y, z, v, overlay_size, os)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;31m#  Black-out the area behind the logo in our original ROI\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[0mimg1_bg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbitwise_and\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mroi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbitwise_not\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;31m#     img1_bgg = cv2.bitwise_and(roig.copy(),roig.copy(),mask = cv2.bitwise_not(maskg))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.4.0) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-2y91i_7w\\opencv\\modules\\core\\src\\arithm.cpp:250: error: (-215:Assertion failed) (mtype == CV_8U || mtype == CV_8S) && _mask.sameSize(*psrc1) in function 'cv::binary_op'\n"
     ]
    }
   ],
   "source": [
    "nose_cascade = cv2.CascadeClassifier('Nose18x15.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('frontalEyes35x16.xml')\n",
    "m = cv2.imread('mustache.png', -1)\n",
    "g = cv2.imread('glasses.png', -1)\n",
    "img = cv2.imread('Before.jpg')\n",
    "\n",
    "grayFrame = cv2.cvtColor(i, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "noses = nose_cascade.detectMultiScale(grayFrame, scaleFactor = 1.3, minNeighbors = 9, minSize = (30, 30), flags = cv2.CASCADE_SCALE_IMAGE)\n",
    "eyes = eye_cascade.detectMultiScale(grayFrame, scaleFactor = 1.3, minNeighbors = 3, minSize = (30, 30), flags = cv2.CASCADE_SCALE_IMAGE)\n",
    "print('noses:', len(noses))\n",
    "print('eyes:', len(eyes))\n",
    "\n",
    "for eye in eyes:\n",
    "    x,y,w,h = eye\n",
    "    cv2.rectangle(img, (x, y), (x + w, y + h), (0,255,0), 2)\n",
    "    \n",
    "for nose in noses:\n",
    "    x,y,w,h = nose\n",
    "    cv2.rectangle(img, (x, y), (x + w, y + h), (0,255,0), 2)\n",
    "\n",
    "\n",
    "# cv2.imshow('Pic',overlay_transparent(i, m, noses[0][0] - 4, noses[0][1] + noses[0][3] - 52, (140,80)))\n",
    "# cv2.imshow('Pic',overlay_transparent(i, g, eyes[0][0] - 17, eyes[0][1] - 15, (400,200)))\n",
    "img = overlay_transparent(img, g, m, eyes[0][0], eyes[0][1], noses[0][0], noses[0][1] + noses[0][3])\n",
    "cv2.imshow('Pic', img)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.rectangle?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
